{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system('pip install -r requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class_names = ['adj', 'int', 'geo', 'pro', 'non']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "\n",
    "weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "model = fasterrcnn_resnet50_fpn_v2(weights=weights)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_fpn.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io.image import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "\n",
    "trans = T.Compose([\n",
    "            T.ToImage(),\n",
    "            T.Resize((600, 600)),\n",
    "            T.ToDtype(torch.float32, scale=True),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "img = read_image(\"path/to/photo\")\n",
    "wigth, height = img.size(1), img.size(2)\n",
    "img = trans(img.to(device))\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    prediction = model(img.unsqueeze(0))[0]\n",
    "\n",
    "labels = [class_names[i] for i in prediction[\"labels\"]]\n",
    "img = (255.0 * (img - img.min()) / (img.max() - img.min())).to(torch.uint8).to('cpu')\n",
    "img = img[:3, ...]\n",
    "box = draw_bounding_boxes(img, boxes=prediction[\"boxes\"],\n",
    "                          labels=labels,\n",
    "                          colors=\"red\",\n",
    "                          width=4)\n",
    "im = to_pil_image(box.detach())\n",
    "im"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
